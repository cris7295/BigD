# Amazon Data Governance & Quality Framework (ETL Pipeline)

## ğŸ“Œ DescripciÃ³n del Proyecto
Este repositorio contiene la implementaciÃ³n tÃ©cnica del Trabajo de InvestigaciÃ³n Final: **"Gobernanza y Calidad de datos para el Ecosistema de e-commerce a Gran Escala"**.

El proyecto consiste en un pipeline **ETL (Extract, Transform, Load)** desarrollado en **Python** que implementa una **Arquitectura Medallion** (Bronze $\to$ Silver $\to$ Gold). Su objetivo es tomar datos transaccionales crudos (CSVs), aplicar un estricto motor de gobernanza (deduplicaciÃ³n, validaciÃ³n de precios, integridad de origen) y generar datasets analÃ­ticos para KPIs de negocio.

## ğŸ“‚ Estructura del Proyecto
El cÃ³digo requiere la siguiente estructura de directorios para funcionar:

```text
/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ bronze/             # [Fuente] Colocar aquÃ­ los CSVs crudos (01_..._Bronze.csv)
â”‚   â”œâ”€â”€ silver/             # [Destino] AquÃ­ se guardan los datos limpios
â”‚   â””â”€â”€ gold/               # [Destino] AquÃ­ se genera el Dashboard de KPIs
â”‚
â”œâ”€â”€ etl_pipeline.py         # Script principal de ejecuciÃ³n (Orquestador)
â””â”€â”€ README.md               # DocumentaciÃ³n tÃ©cnica

âš™ï¸ Requisitos TÃ©cnicos
Python 3.8+

LibrerÃ­as: pandas, numpy

Espacio en disco: Al menos 500MB libres.

ğŸš€ Instrucciones de EjecuciÃ³n
1. PreparaciÃ³n de Datos (Capa Bronze)
El script asume que los datos crudos ya han sido extraÃ­dos y convertidos a CSV.

Paso CrÃ­tico: Debes crear manualmente la carpeta data/bronze/ y pegar dentro los siguientes archivos fuente:

01_Meta_Bronze.csv (CatÃ¡logo de Productos sucio)

01_Reviews_Bronze.csv (Transacciones/ReseÃ±as sucias)

2. InstalaciÃ³n de Dependencias
Ejecutar en la terminal de Visual Studio Code:

Bash

pip install pandas numpy
3. Ejecutar el Pipeline
El sistema detectarÃ¡ los archivos en Bronze y procesarÃ¡ las capas Silver y Gold automÃ¡ticamente.

Bash

python etl_pipeline.py
ğŸ§  Arquitectura de Datos (Medallion)
El pipeline procesa la informaciÃ³n en tres capas secuenciales:

ğŸ¥‰ Capa Bronze (Raw Input)
UbicaciÃ³n: data/bronze/

Estado: Datos crudos "As-Is". Se preservan duplicados, precios nulos y spam para tener una lÃ­nea base de auditorÃ­a.

ğŸ¥ˆ Capa Silver (Gobernanza & Calidad)
UbicaciÃ³n: data/silver/

Motor de Calidad:

Unicidad: DeduplicaciÃ³n por ID de producto y huella digital de la reseÃ±a (usuario+texto+tiempo).

Consistencia de Negocio: EliminaciÃ³n de productos con price <= 0.

Integridad de Origen: Filtrado estricto donde verified_purchase == True. Se descarta trÃ¡fico de bots/spam.

ğŸ¥‡ Capa Gold (Valor & KPIs)
UbicaciÃ³n: data/gold/

Archivo Final: 03_Dashboard_Gold.csv

Modelado: Join entre CatÃ¡logo y Reviews + Enriquecimiento con NLP.

KPIs Generados:

OTD (On-Time Delivery): DetecciÃ³n de palabras clave como "late", "delay".

Riesgo de DevoluciÃ³n: DetecciÃ³n de intenciÃ³n de retorno ("return", "broken").
